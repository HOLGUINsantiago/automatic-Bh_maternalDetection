{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d2ebd7",
   "metadata": {},
   "source": [
    "# Launch of Deepethogram - Infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575caed",
   "metadata": {},
   "source": [
    "## 1. Copy movies\n",
    "This script will repare all videos (corrupted for one reason I ignore), and will then add them using deepethogram fonction (it calculate std and mean whhile adding the videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from deepethogram import projects\n",
    "import re\n",
    "import shlex\n",
    "import pandas as pd\n",
    "\n",
    "def repair_video_with_ffmpeg(video_path, output_dir):\n",
    "    filename = os.path.basename(video_path)\n",
    "    name_no_ext = os.path.splitext(filename)[0]\n",
    "    safe_name = name_no_ext.replace(\" \", \"\")\n",
    "    repaired_filename = f\"{safe_name}.mp4\"\n",
    "    repaired_path = os.path.join(output_dir, repaired_filename)\n",
    "\n",
    "    if os.path.exists(repaired_path):\n",
    "        print(f\"[‚úì] Already repaired: {repaired_filename}\")\n",
    "        return repaired_path\n",
    "    try:\n",
    "        cmd = f\"\"\"ffmpeg -y -err_detect ignore_err -i \"{video_path}\" \\\n",
    "        -vf \"fps=30\" -c:v libx264 -preset veryfast -crf 24 \\\n",
    "        -c:a aac -strict experimental \"{repaired_path}\" \"\"\"\n",
    "        \n",
    "        subprocess.run(shlex.split(cmd), check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        return repaired_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[‚úó] Error repairing {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def ajouter_tous_videos_au_projet(project_config_path, root_video_dir, mode='copy', extensions=None, csv_filter_path=None):\n",
    "    if extensions is None:\n",
    "        extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv']\n",
    "\n",
    "    # Cargar proyecto\n",
    "    project = projects.load_config(project_config_path)\n",
    "    execution_dir = os.getcwd()\n",
    "\n",
    "    # Cargar CSV con nombres de videos si se proporciona\n",
    "    allowed_video_names = None\n",
    "    if csv_filter_path is not None and os.path.exists(csv_filter_path):\n",
    "        df_filter = pd.read_csv(csv_filter_path)\n",
    "        # Usamos el nombre sin extensi√≥n para comparar\n",
    "        allowed_video_names = set(os.path.splitext(v)[0] for v in df_filter['video_name'].values)\n",
    "        print(f\"[üîé] Usando filtro de CSV con {len(allowed_video_names)} nombres.\")\n",
    "\n",
    "    # Recopilar los paths v√°lidos\n",
    "    videos_paths = []\n",
    "    pattern = re.compile(r\".*_(\\d{2})-(\\d{2})-(\\d{2})\") \n",
    "\n",
    "    for root, dirs, files in os.walk(root_video_dir):\n",
    "        # Saltar carpetas que contienen \"aborted\" o \"post\" en su ruta\n",
    "        if any(x in root.lower() for x in [\"aborted\", \"post\"]):\n",
    "            continue\n",
    "        for file in files:\n",
    "            match = pattern.match(file)\n",
    "            if match and not file.lower().startswith(\"cont\") and not file.lower().startswith(\"lnb\"):\n",
    "                name_no_ext = os.path.splitext(file)[0].replace(\" \", \"\")\n",
    "                hour = int(match.group(1))\n",
    "                min =  int(match.group(2))\n",
    "                if (hour < 7 or (hour == 7 and min < 29)) or hour >= 20:\n",
    "                    if os.path.splitext(file)[1].lower() in extensions:\n",
    "                        if allowed_video_names is None or name_no_ext in allowed_video_names:\n",
    "                            full_path = os.path.join(root, file)\n",
    "                            videos_paths.append(full_path)\n",
    "\n",
    "    print(f\"üîç Found {len(videos_paths)} video(s) to check and add.\")\n",
    "    \n",
    "    cont = 0\n",
    "    for video_path in videos_paths:\n",
    "        repaired_path = repair_video_with_ffmpeg(video_path, output_dir=execution_dir)\n",
    "        if repaired_path:\n",
    "            cont += 1\n",
    "            try:\n",
    "                new_path = projects.add_video_to_project(project, repaired_path, mode=mode)\n",
    "                print(f\"[+] Added: {repaired_path} ‚Üí {new_path} . {cont} / {len(videos_paths)}\")\n",
    "                os.remove(repaired_path)\n",
    "            except Exception as e:\n",
    "                os.remove(repaired_path)\n",
    "        else:\n",
    "            print(f\"[!] Skipped: {video_path} (repair failed)\")\n",
    "\n",
    "# === CONFIGURACI√ìN ===\n",
    "config_path = r\"D:\\LBN\\Maternal_auto_classification_manualVal_deepethogram\\project_config.yaml\"\n",
    "videos_dir = r\"Z:\\Marion\\2. Tests - Manuels - Data\\3. LBN\\3. Rawdata\\1. VEAVE_LBN-CONT\"\n",
    "csv_path = r\"D:\\LBN\\selected_videos_balanced_filtered.csv\"  # CSV con columna 'video_name'\n",
    "\n",
    "ajouter_tous_videos_au_projet(config_path, videos_dir, mode='copy', csv_filter_path=csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa711137",
   "metadata": {},
   "source": [
    "## 2. Infer videos\n",
    "We'll then pass our model through the new data to predict the behaviours found in each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7110627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "python_path = r\"C:\\Users\\TeamGranon\\anaconda3\\envs\\deg_solo\\python.exe\"\n",
    "script_path = r\"D:\\LBN\\Maternal_auto_classification_TS7_deepethogram\\infering.py\"\n",
    "\n",
    "subprocess.run([python_path, script_path], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f729406",
   "metadata": {},
   "source": [
    "## 3. Transform output\n",
    "We'll finally transform the .h5 output file on a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepethogram.postprocessing import get_postprocessor_from_cfg\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from deepethogram import projects\n",
    "\n",
    "def convertir_outputs_a_csv_con_postprocess(data_dir, cfg):\n",
    "    config = projects.load_config(cfg)\n",
    "    output_dir = r\"D:\\LBN\\Maternal_auto_classification_TS7_deepethogram\\Maternal_behaviour_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('outputs.h5'):\n",
    "                outputs_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with h5py.File(outputs_path, 'r') as f:\n",
    "                        group = f['resnet18']\n",
    "                        probabilities = group['P'][:]\n",
    "                        thresholds = group['thresholds'][:]\n",
    "                        class_names = [x.decode('utf-8') for x in group['class_names'][:]]\n",
    "\n",
    "                    postprocessor = get_postprocessor_from_cfg(config, thresholds)\n",
    "                    estimated_labels = postprocessor(probabilities)\n",
    "                    df = pd.DataFrame(estimated_labels, columns=class_names)\n",
    "\n",
    "                    # Nouveau nom de fichier avec m√™me base mais dans le dossier output\n",
    "                    base_name = os.path.splitext(os.path.basename(outputs_path))[0]\n",
    "                    prediction_fname = os.path.join(output_dir, base_name + '_labels_predictions.csv')\n",
    "                    df.to_csv(prediction_fname, index=False)\n",
    "                    print(f\"[‚úì] Guardado postprocesado: {prediction_fname}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[‚úó] Error con {outputs_path}: {e}\")\n",
    "\n",
    "# Appel\n",
    "directorio_data = r\"D:\\LBN\\Maternal_auto_classification_TS7_deepethogram\\DATA\"\n",
    "cfg = r\"D:\\LBN\\Maternal_auto_classification_TS7_deepethogram\\project_config.yaml\"\n",
    "convertir_outputs_a_csv_con_postprocess(directorio_data, cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deg_solo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
