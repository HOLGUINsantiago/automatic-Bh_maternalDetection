{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d2ebd7",
   "metadata": {},
   "source": [
    "# Launch of Deepethogram - Infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575caed",
   "metadata": {},
   "source": [
    "## 1. Copy movies\n",
    "This script will repare all videos (corrupted for one reason I ignore), and will then add them using deepethogram fonction (it calculate std and mean whhile adding the videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from deepethogram import projects\n",
    "import re\n",
    "\n",
    "def repair_video_with_ffmpeg(video_path, output_dir):\n",
    "    import shlex\n",
    "\n",
    "    filename = os.path.basename(video_path)\n",
    "    name_no_ext = os.path.splitext(filename)[0]\n",
    "    safe_name = name_no_ext.replace(\" \", \"\")\n",
    "    repaired_filename = f\"{safe_name}.mp4\"\n",
    "    repaired_path = os.path.join(output_dir, repaired_filename)\n",
    "\n",
    "    if os.path.exists(repaired_path):\n",
    "        print(f\"[âœ“] Already repaired: {repaired_filename}\")\n",
    "        return repaired_path\n",
    "\n",
    "    print(f\"[âš™] Repairing: {filename}\")\n",
    "    try:\n",
    "        cmd = f\"\"\"ffmpeg -y -err_detect ignore_err -i \"{video_path}\" \\\n",
    "        -vf \"fps=30\" -c:v libx264 -preset veryfast -crf 24 \\\n",
    "        -c:a aac -strict experimental \"{repaired_path}\" \"\"\"\n",
    "        \n",
    "        subprocess.run(shlex.split(cmd), check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        return repaired_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[âœ—] Error repairing {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def ajouter_tous_videos_au_projet(project_config_path, root_video_dir, mode='copy', extensions=None):\n",
    "    if extensions is None:\n",
    "        extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv']\n",
    "\n",
    "    project = projects.load_config(project_config_path)\n",
    "    execution_dir = os.getcwd()\n",
    "\n",
    "    videos_paths = []\n",
    "    pattern = re.compile(r\".*_(\\d{2})-(\\d{2})-(\\d{2})\") \n",
    "    for root, dirs, files in os.walk(root_video_dir):\n",
    "        for file in files:\n",
    "            match = pattern.match(file)\n",
    "            if match and \"CONT\" in file and not file.startswith(\"CONT\"):\n",
    "                hour = int(match.group(1))\n",
    "                if 8 > hour or hour >= 20:\n",
    "                    if os.path.splitext(file)[1].lower() in extensions:\n",
    "                        full_path = os.path.join(root, file)\n",
    "                        videos_paths.append(full_path)\n",
    "\n",
    "    print(f\"Found {len(videos_paths)} videos to check and add.\")\n",
    "    cont = 0\n",
    "    for video_path in videos_paths:\n",
    "        video_name = os.path.basename(video_path)\n",
    "\n",
    "        repaired_path = repair_video_with_ffmpeg(video_path, output_dir=execution_dir)\n",
    "        if repaired_path:\n",
    "            cont += 1\n",
    "            try:\n",
    "                new_path = projects.add_video_to_project(project, repaired_path, mode=mode)\n",
    "                print(f\"[+] Added: {repaired_path} â†’ {new_path} . {cont} / {len(videos_paths)}\")\n",
    "                os.remove(repaired_path)\n",
    "                print(f\"[ðŸ—‘] Deleted temporary file: {repaired_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[âœ—] Error adding to project {repaired_path}: {e}\")\n",
    "                os.remove(repaired_path)\n",
    "                print(f\"[ðŸ—‘] Deleted temporary file: {repaired_path}\")\n",
    "        else:\n",
    "            print(f\"[!] Skipped: {video_path} (repair failed)\")\n",
    "\n",
    "# === CONFIGURACIÃ“N ===\n",
    "config_path = r\"D:\\LBN\\Maternal_auto_classification_TS7_deepethogram\\project_config.yaml\"\n",
    "videos_dir = r\"Z:\\Marion\\2. Tests - Manuels - Data\\3. LBN\\3. Rawdata\\1. VEAVE_LBN-CONT\"\n",
    "\n",
    "ajouter_tous_videos_au_projet(config_path, videos_dir, mode='copy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa711137",
   "metadata": {},
   "source": [
    "## 2. Infer videos\n",
    "We'll then pass our model through the new data to predict the behaviours found in each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7110627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Comando para activar el entorno y ejecutar el script en Windows\n",
    "cmd = 'conda activate deg_env && python d:\\\\LBN\\\\tryInfer.py'\n",
    "\n",
    "# Ejecutar el comando en shell\n",
    "subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f729406",
   "metadata": {},
   "source": [
    "## 3. Transform output\n",
    "We'll finally transform the .h5 output file on a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepethogram.postprocessing import get_postprocessor_from_cfg\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from deepethogram import projects\n",
    "\n",
    "def convertir_outputs_a_csv_con_postprocess(data_dir, cfg):\n",
    "    config = projects.load_config(cfg)\n",
    "    output_dir = r\"D:\\LBN\\Maternal_behaviour_results_cont\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('outputs.h5'):\n",
    "                outputs_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with h5py.File(outputs_path, 'r') as f:\n",
    "                        group = f['resnet18']\n",
    "                        probabilities = group['P'][:]\n",
    "                        thresholds = group['thresholds'][:]\n",
    "                        class_names = [x.decode('utf-8') for x in group['class_names'][:]]\n",
    "\n",
    "                    postprocessor = get_postprocessor_from_cfg(config, thresholds)\n",
    "                    estimated_labels = postprocessor(probabilities)\n",
    "                    df = pd.DataFrame(estimated_labels, columns=class_names)\n",
    "\n",
    "                    # Nouveau nom de fichier avec mÃªme base mais dans le dossier output\n",
    "                    base_name = os.path.splitext(os.path.basename(outputs_path))[0]\n",
    "                    prediction_fname = os.path.join(output_dir, base_name + '_labels_predictions.csv')\n",
    "                    df.to_csv(prediction_fname, index=False)\n",
    "                    print(f\"[âœ“] Guardado postprocesado: {prediction_fname}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[âœ—] Error con {outputs_path}: {e}\")\n",
    "\n",
    "# Appel\n",
    "directorio_data = r\"D:\\LBN\\Maternal_auto_classification_TS7_deepethogram\\DATA\"\n",
    "cfg = r\"D:\\LBN\\Maternal_auto_classification_TS7_deepethogram\\project_config.yaml\"\n",
    "convertir_outputs_a_csv_con_postprocess(directorio_data, cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deg_solo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
